{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizer for ROCO dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are several things to do before visualizaation.\n",
    "1. Place your ROCO dataset under `iRM_Autonomy_2020\\dnn\\data\\DJI ROCO` and place the `DJI ROCO` folder.\n",
    "2. Run the `roco.py` in order to generate TFRecord files from ROCO dataset.\n",
    "3. Run the codes below to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from utils import CLASS_NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please say how many samples you want to show per TFRecord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_per_TFRecord = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FEATURE_MAP = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'object': tf.io.FixedLenFeature([], tf.string),\n",
    "    'bbox': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    examples = tf.io.parse_single_example(example_proto, IMAGE_FEATURE_MAP)\n",
    "    return examples\n",
    "\n",
    "\n",
    "def draw_outputs(img, outputs, class_names):\n",
    "    boxes, objectness, classes, nums = outputs\n",
    "    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]\n",
    "    wh = np.flip(img.shape[0:2])\n",
    "    for i in range(nums):\n",
    "        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
    "        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n",
    "        img = cv2.putText(img, '{} {:.4f}'.format(\n",
    "            class_names[int(classes[i])], objectness[i]),\n",
    "                          x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### the 1 dataset\n",
      "         the 1 picture\n",
      "         the 2 picture\n",
      "         the 3 picture\n",
      "         the 4 picture\n",
      "         the 5 picture\n",
      "         the 6 picture\n",
      "### the 2 dataset\n",
      "         the 1 picture\n",
      "         the 2 picture\n",
      "         the 3 picture\n",
      "         the 4 picture\n",
      "         the 5 picture\n",
      "         the 6 picture\n",
      "### the 3 dataset\n",
      "         the 1 picture\n",
      "         the 2 picture\n",
      "         the 3 picture\n",
      "         the 4 picture\n",
      "         the 5 picture\n",
      "         the 6 picture\n",
      "### the 4 dataset\n",
      "         the 1 picture\n",
      "         the 2 picture\n",
      "         the 3 picture\n",
      "         the 4 picture\n",
      "         the 5 picture\n",
      "         the 6 picture\n"
     ]
    }
   ],
   "source": [
    "folder_ids = os.listdir('../DJI ROCO TFRecord/')\n",
    "for n, training_id in enumerate(folder_ids):\n",
    "    training_data = tf.data.TFRecordDataset('../DJI ROCO TFRecord/' + training_id)\n",
    "    data_set = training_data.map(_parse_image_function)\n",
    "    tf.print('### the {} dataset'.format(n + 1), output_stream=sys.stdout)\n",
    "    for m, image_features in enumerate(data_set):\n",
    "        tf.print('         the {} picture'.format(m + 1), output_stream=sys.stdout)\n",
    "        image_raw = tf.io.decode_image(image_features['image'], channels=3)\n",
    "        objects = tf.io.parse_tensor(image_features['object'], tf.int32)\n",
    "        bboxes = tf.io.parse_tensor(image_features['bbox'], tf.float32)\n",
    "        width = image_raw.shape[1]\n",
    "        height = image_raw.shape[0]\n",
    "        boxes = []\n",
    "        scores = []\n",
    "        classes = []\n",
    "        for p, label in enumerate(objects):\n",
    "            boxes.append([bboxes[p][0] / width,\n",
    "                          bboxes[p][1] / height,\n",
    "                          bboxes[p][2] / width,\n",
    "                          bboxes[p][3] / height])\n",
    "            scores.append(1)\n",
    "            classes.append(objects[p])\n",
    "        nums = [len(boxes)]\n",
    "        boxes = [boxes]\n",
    "        scores = [scores]\n",
    "        classes = [classes]\n",
    "        img = cv2.cvtColor(image_raw.numpy(), cv2.COLOR_RGB2BGR)\n",
    "        img = draw_outputs(img, (boxes, scores, classes, nums), CLASS_NAMES)\n",
    "        cv2.imshow(\"RM Training Set\", img)\n",
    "        cv2.waitKey(0)\n",
    "        if m == sample_per_TFRecord - 1:\n",
    "            break\n",
    "cv2.destroyWindow(\"RM Training Set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
